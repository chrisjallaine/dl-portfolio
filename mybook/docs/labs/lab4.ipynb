{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f9c65c",
   "metadata": {},
   "source": [
    " ##  Understanding Deep Learning : Lab 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab9dbc",
   "metadata": {},
   "source": [
    "## Linear Regression with a Regression Dataset <br>\n",
    "In this activity, we applied linear regression using PyTorch on the real-world Diabetes dataset from scikit-learn.\n",
    "We began by loading and normalizing the input features, then converted the data into PyTorch tensors and created a DataLoader for mini-batch training.\n",
    "Next, we defined a Linear Regression model using a single fully connected layer, trained it with Mean Squared Error (MSE) loss and Stochastic Gradient Descent (SGD), and monitored the training loss over multiple epochs.\n",
    "Finally, we tested the model by comparing its predicted output with the actual target value to evaluate its learning performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f0fd0",
   "metadata": {},
   "source": [
    "Here is the given problem setup:\n",
    "\n",
    "<img src=\"https://i.ibb.co/Fk0pP2wR/Screenshot-2025-09-13-at-2-14-30-PM.png\" width=\"1200\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d49ea",
   "metadata": {},
   "source": [
    "### IMPLEMENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32495eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Linear Regression with PyTorch\n",
    "# Dataset: Diabetes dataset (real-world regression)\n",
    "# ----------------------------\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ef1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target   # X = features, y = target (disease progression score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336b5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features (important for regression!)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b42bf9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "inputs = torch.tensor(X, dtype=torch.float32)\n",
    "targets = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)  # reshape for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142f8273",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create DataLoader for batch training\n",
    "train_ds = TensorDataset(inputs, targets)          # wrap tensors in a dataset\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)  # 16 samples per batch##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5dccd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple Linear Regression model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  # single linear layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c2e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = LinearRegressionModel(input_dim=inputs.shape[1], output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5216dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.MSELoss()                     # Mean Squared Error for regression\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfca46bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 2471.2607\n",
      "Epoch [20/100], Loss: 2595.7314\n",
      "Epoch [30/100], Loss: 2083.4661\n",
      "Epoch [40/100], Loss: 5486.0869\n",
      "Epoch [50/100], Loss: 316.9049\n",
      "Epoch [60/100], Loss: 3338.3445\n",
      "Epoch [70/100], Loss: 2962.1626\n",
      "Epoch [80/100], Loss: 3420.6724\n",
      "Epoch [90/100], Loss: 3563.8625\n",
      "Epoch [100/100], Loss: 2373.8159\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:       # get mini-batches\n",
    "        # Forward pass: compute prediction\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "\n",
    "        # Backward pass: compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c792f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Prediction:\n",
      "Predicted value: 204.79237365722656\n",
      "Actual value   : 151.0\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a sample\n",
    "with torch.no_grad():  # no gradients needed for testing\n",
    "    sample_input = inputs[0].unsqueeze(0)   # take the first sample\n",
    "    predicted = model(sample_input)\n",
    "    print(\"\\nExample Prediction:\")\n",
    "    print(\"Predicted value:\", predicted.item())\n",
    "    print(\"Actual value   :\", targets[0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28244df",
   "metadata": {},
   "source": [
    "## Conclusions / Learnings\n",
    "<div style=\"border: 2px solid #4CAF50; background-color: #e8f5e9; padding: 15px; border-radius: 10px; margin-top: 10px; margin-bottom: 10px;\">\n",
    "- Training a linear regression model in PyTorch involves defining a simple network, selecting a suitable loss function (MSE), and using an optimizer (SGD) to update weights.  \n",
    "- With enough epochs, the model parameters converge and approximate the true underlying relationship between input and output.  \n",
    "- Batch training (e.g., batch size = 8) helps improve efficiency and stability during gradient updates.  \n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- PyTorch provides <strong>TensorDataset</strong> and <strong>DataLoader</strong> for efficient dataset handling and batching.  \n",
    "- A simple <strong>linear model</strong> can capture patterns effectively, even with synthetic data.  \n",
    "- The training loop follows the sequence: <strong>Forward pass → Loss calculation → Backpropagation → Optimization</strong>.  \n",
    "- <strong> updates weights step by step based on computed gradients.  \n",
    "- <strong>Data preprocessing and normalization</strong> can improve training stability and convergence speed.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
