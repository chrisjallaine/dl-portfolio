
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Understanding Deep Learning : Lab 4 &#8212; ChrisJallaine&#39;s Deep Learning Portfolio</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/labs/lab4';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="LABORATORY TASK 5" href="lab5.html" />
    <link rel="prev" title="Understanding Deep Learning : Lab 3" href="lab3.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo1.gif" class="logo__image only-light" alt="ChrisJallaine's Deep Learning Portfolio - Home"/>
    <script>document.write(`<img src="../../_static/logo1.gif" class="logo__image only-dark" alt="ChrisJallaine's Deep Learning Portfolio - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    About Me
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="README.html">üíª Laboratory</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="lab1.html">Foundational Concept of Deep Learning: Lab1</a></li>

<li class="toctree-l2"><a class="reference internal" href="lab2.html">Understanding Deep Learning : Lab 2</a></li>


<li class="toctree-l2"><a class="reference internal" href="lab3.html">Understanding Deep Learning : Lab 3</a></li>

<li class="toctree-l2 current active"><a class="current reference internal" href="#">Understanding Deep Learning : Lab 4</a></li>


<li class="toctree-l2"><a class="reference internal" href="lab5.html">LABORATORY TASK 5</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab6.html">Laboratory Activity 6</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../projects/README.html">üóÇÔ∏è Projects</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/chrisjallaine/dl-portfolio.git" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/chrisjallaine/dl-portfolio.git/issues/new?title=Issue%20on%20page%20%2Fdocs/labs/lab4.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/docs/labs/lab4.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Understanding Deep Learning : Lab 4</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Understanding Deep Learning : Lab 4</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-a-regression-dataset">Linear Regression with a Regression Dataset <br/></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implemention">IMPLEMENTION</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-model">Defining The Model</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusions-learnings">Conclusions / Learnings</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="understanding-deep-learning-lab-4">
<h1>Understanding Deep Learning : Lab 4<a class="headerlink" href="#understanding-deep-learning-lab-4" title="Link to this heading">#</a></h1>
</section>
<section id="linear-regression-with-a-regression-dataset">
<h1>Linear Regression with a Regression Dataset <br><a class="headerlink" href="#linear-regression-with-a-regression-dataset" title="Link to this heading">#</a></h1>
<p>In this activity, we applied linear regression using PyTorch on the real-world Diabetes dataset from scikit-learn.
We began by loading and normalizing the input features, then converted the data into PyTorch tensors and created a DataLoader for mini-batch training.
Next, we defined a Linear Regression model using a single fully connected layer, trained it with Mean Squared Error (MSE) loss and Stochastic Gradient Descent (SGD), and monitored the training loss over multiple epochs.
Finally, we tested the model by comparing its predicted output with the actual target value to evaluate its learning performance.</p>
<p>Here is the given problem setup:</p>
<img src="https://i.ibb.co/Fk0pP2wR/Screenshot-2025-09-13-at-2-14-30-PM.png" width="1200">
<section id="implemention">
<h2>IMPLEMENTION<a class="headerlink" href="#implemention" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ============================</span>
<span class="c1"># 1. Import Libraries</span>
<span class="c1"># ============================</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_california_housing</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ============================</span>
<span class="c1"># 2. Load and Preprocess Dataset</span>
<span class="c1"># ============================</span>


<span class="c1"># Load dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Normalize features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert to PyTorch tensors</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create DataLoader (batch_size = 8)</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="defining-the-model">
<h2>Defining The Model<a class="headerlink" href="#defining-the-model" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ============================</span>
<span class="c1"># 3. Define Model with 2 Layers</span>
<span class="c1"># ============================</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LinearRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">input_dim</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>   <span class="c1"># number of features = 8</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">32</span>               <span class="c1"># hidden units</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ============================</span>
<span class="c1"># 4. Define Loss and Optimizer</span>
<span class="c1"># ============================</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ============================</span>
<span class="c1"># 5. Training Loop (1000 Epochs)</span>
<span class="c1"># ============================</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
        <span class="c1"># Forward pass</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>

        <span class="c1"># Backward pass</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    
    <span class="c1"># Print every 100 epochs</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">], Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">line</span> <span class="mi">15</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="c1"># Backward pass</span>
<span class="ne">---&gt; </span><span class="mi">15</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="nn">File /opt/anaconda3/lib/python3.12/site-packages/torch/_compile.py:32,</span> in <span class="ni">_disable_dynamo.&lt;locals&gt;.inner</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">29</span>     <span class="n">disable_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">disable</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">recursive</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">30</span>     <span class="n">fn</span><span class="o">.</span><span class="n">__dynamo_disable</span> <span class="o">=</span> <span class="n">disable_fn</span>
<span class="ne">---&gt; </span><span class="mi">32</span> <span class="k">return</span> <span class="n">disable_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:745,</span> in <span class="ni">DisableContext.__call__.&lt;locals&gt;._fn</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">741</span> <span class="n">prior_skip_guard_eval_unsafe</span> <span class="o">=</span> <span class="n">set_skip_guard_eval_unsafe</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">742</span>     <span class="n">_is_skip_guard_eval_unsafe_stance</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">743</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">744</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">745</span>     <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">746</span> <span class="k">finally</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">747</span>     <span class="n">_maybe_set_eval_frame</span><span class="p">(</span><span class="n">prior</span><span class="p">)</span>

<span class="nn">File /opt/anaconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:970,</span> in <span class="ni">Optimizer.zero_grad</span><span class="nt">(self, set_to_none)</span>
<span class="g g-Whitespace">    </span><span class="mi">967</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">968</span>     <span class="n">per_device_and_dtype_grads</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">970</span> <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">record_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_grad_profile_name</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">971</span>     <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">972</span>         <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]:</span>

<span class="nn">File /opt/anaconda3/lib/python3.12/site-packages/torch/autograd/profiler.py:769,</span> in <span class="ni">record_function.__exit__</span><span class="nt">(self, exc_type, exc_value, traceback)</span>
<span class="g g-Whitespace">    </span><span class="mi">767</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">768</span>     <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">DisableTorchFunctionSubclass</span><span class="p">():</span>
<span class="ne">--&gt; </span><span class="mi">769</span>         <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">_record_function_exit</span><span class="o">.</span><span class="n">_RecordFunction</span><span class="p">(</span><span class="n">record</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">770</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">771</span>     <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">_record_function_exit</span><span class="p">(</span><span class="n">record</span><span class="p">)</span>

<span class="nn">File /opt/anaconda3/lib/python3.12/site-packages/torch/_ops.py:947,</span> in <span class="ni">TorchBindOpOverload.__call__</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">946</span> <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">/</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">947</span>     <span class="k">if</span> <span class="n">_must_dispatch_in_python</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">948</span>         <span class="c1"># When any inputs are FakeScriptObject, we need to</span>
<span class="g g-Whitespace">    </span><span class="mi">949</span>         <span class="c1"># skip c++ dispatcher and dispatch in python through _get_dispatch of python_dispatcher</span>
<span class="g g-Whitespace">    </span><span class="mi">950</span>         <span class="c1"># because C++ dispatcher will check the schema and cannot recognize FakeScriptObject.</span>
<span class="g g-Whitespace">    </span><span class="mi">951</span>         <span class="c1">#</span>
<span class="g g-Whitespace">    </span><span class="mi">952</span>         <span class="c1"># Note:</span>
<span class="g g-Whitespace">    </span><span class="mi">953</span>         <span class="c1"># 1. We only register the torchbind op temporarily as effectful op because we only want</span>
<span class="g g-Whitespace">    </span><span class="mi">954</span>         <span class="c1">#    the effect token functionalization logic to be applied during tracing. Otherwise, the behavior</span>
<span class="g g-Whitespace">    </span><span class="mi">955</span>         <span class="c1">#    of the eagerly executing the op might change after tracing.</span>
<span class="g g-Whitespace">    </span><span class="mi">956</span>         <span class="c1"># 2. We don&#39;t want to register the op as effectful for all torchbind ops in ctor because this might</span>
<span class="g g-Whitespace">    </span><span class="mi">957</span>         <span class="c1">#    cause unexpected behavior for some autograd.profiler ops e.g. profiler._record_function_exit._RecordFunction.</span>
<span class="g g-Whitespace">    </span><span class="mi">958</span>         <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_register_as_effectful_op_temporarily</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">959</span>             <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dispatch_in_python</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fallthrough_keys</span><span class="p">())</span>

<span class="nn">File /opt/anaconda3/lib/python3.12/site-packages/torch/_ops.py:1001,</span> in <span class="ni">_must_dispatch_in_python</span><span class="nt">(args, kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1000</span> <span class="k">def</span><span class="w"> </span><span class="nf">_must_dispatch_in_python</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1001</span>     <span class="k">return</span> <span class="n">pytree</span><span class="o">.</span><span class="n">tree_any</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1002</span>         <span class="k">lambda</span> <span class="n">obj</span><span class="p">:</span> <span class="nb">isinstance</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1003</span>             <span class="n">obj</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_library</span><span class="o">.</span><span class="n">fake_class_registry</span><span class="o">.</span><span class="n">FakeScriptObject</span>
<span class="g g-Whitespace">   </span><span class="mi">1004</span>         <span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1005</span>         <span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1006</span>     <span class="p">)</span>

<span class="nn">File /opt/anaconda3/lib/python3.12/site-packages/torch/utils/_pytree.py:1230,</span> in <span class="ni">tree_any</span><span class="nt">(pred, tree, is_leaf)</span>
<span class="g g-Whitespace">   </span><span class="mi">1224</span> <span class="k">def</span><span class="w"> </span><span class="nf">tree_any</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1225</span>     <span class="n">pred</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="nb">bool</span><span class="p">],</span>
<span class="g g-Whitespace">   </span><span class="mi">1226</span>     <span class="n">tree</span><span class="p">:</span> <span class="n">PyTree</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1227</span>     <span class="n">is_leaf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">PyTree</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1228</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1229</span>     <span class="n">flat_args</span> <span class="o">=</span> <span class="n">tree_iter</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">is_leaf</span><span class="o">=</span><span class="n">is_leaf</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1230</span>     <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">flat_args</span><span class="p">))</span>

<span class="nn">File /opt/anaconda3/lib/python3.12/site-packages/torch/utils/_pytree.py:925,</span> in <span class="ni">tree_iter</span><span class="nt">(tree, is_leaf)</span>
<span class="g g-Whitespace">    </span><span class="mi">923</span>     <span class="k">yield</span> <span class="n">tree</span>
<span class="g g-Whitespace">    </span><span class="mi">924</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">925</span>     <span class="n">node_type</span> <span class="o">=</span> <span class="n">_get_node_type</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">926</span>     <span class="n">flatten_fn</span> <span class="o">=</span> <span class="n">SUPPORTED_NODES</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span><span class="o">.</span><span class="n">flatten_fn</span>
<span class="g g-Whitespace">    </span><span class="mi">927</span>     <span class="n">child_pytrees</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flatten_fn</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>

<span class="nn">File /opt/anaconda3/lib/python3.12/site-packages/torch/utils/_pytree.py:692,</span> in <span class="ni">_get_node_type</span><span class="nt">(tree)</span>
<span class="g g-Whitespace">    </span><span class="mi">688</span>         <span class="k">return</span> <span class="kc">False</span>
<span class="g g-Whitespace">    </span><span class="mi">689</span>     <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">692</span> <span class="k">def</span><span class="w"> </span><span class="nf">_get_node_type</span><span class="p">(</span><span class="n">tree</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">693</span>     <span class="k">if</span> <span class="n">_is_namedtuple_instance</span><span class="p">(</span><span class="n">tree</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">694</span>         <span class="k">return</span> <span class="n">namedtuple</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<p>The machine learning model trained on the California Housing dataset showed successful learning with an overall decrease in loss from 0.4483 (Epoch 100) down to a minimum of 0.0972 at Epoch 900. This demonstrates the model‚Äôs ability to fit the training data effectively. However, the training run was marked by significant instability, most notably a major spike in loss to 1.6435 at Epoch 400, which strongly suggests the occurrence of exploding gradients due to an overly large learning rate or data batch issues. Crucially, the loss then increased to 0.2740 by the final Epoch 1000, indicating that the model began to overfit or diverge after reaching its optimum performance at Epoch 900. Therefore, the optimal model is found at Epoch 900, and future training should incorporate gradient clipping and early stopping based on a validation loss metric to ensure stability and generalization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ============================</span>
<span class="c1"># 6. Plot Training Loss</span>
<span class="c1"># ============================</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;MSE Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training Loss Curve (California Housing)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/df39f9507220d0058c6fb08d64aa88b84ce7d3e63af4f9e5bdd260e00fd5cc08.png" src="../../_images/df39f9507220d0058c6fb08d64aa88b84ce7d3e63af4f9e5bdd260e00fd5cc08.png" />
</div>
</div>
<p>The training loss curve for the California Housing model shows a highly unstable and volatile learning process over 1000 epochs, characterized by constant, sharp oscillations and several catastrophic spikes (the largest exceeding 2.0 near Epoch 400). This severe volatility is a definitive sign of exploding gradients and an overly high learning rate, which prevents the model from achieving smooth, reliable convergence. While the model occasionally achieved a very low loss, hitting its overall minimum of 0.0972 at Epoch 900, the high-variance behavior means it was constantly overshooting the optimal solution. Furthermore, the loss rose significantly to 0.2740 by the final epoch, indicating that overfitting or divergence began after Epoch 900, making the model state at the minimum loss the most effective version.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ============================</span>
<span class="c1"># 7. Model Evaluation</span>
<span class="c1"># ============================</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">true_values</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># Compute metrics</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">true_values</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">true_values</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Final MSE: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R¬≤ Score: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Final MSE: 0.2832
R¬≤ Score: 0.7873
</pre></div>
</div>
</div>
</div>
<p><strong>Based on results:</strong></p>
<p>The model demonstrated strong overall predictive power, achieving a final R2.
The score of 0.7873 on the validation set, meaning it explains nearly 79% of the variance in the median house values. The final Mean Squared Error (MSE) of 0.2832 on the validation data is also reasonably low. However, this success was achieved despite a training process that was highly unstable and volatile, as shown by the erratic loss curve and catastrophic spikes (the largest exceeding 2.0). This instability points to issues with the learning rate and likely exploding gradients. The most critical finding when comparing training and validation is the evidence of overfitting: the minimum training loss (0.0972 at Epoch 900) is significantly lower than the final validation MSE (0.2832). This gap confirms that the model learned the training noise well, and the high training volatility contributed to a loss in generalization performance. To improve the model, the next steps must focus on stabilizing training by reducing the learning rate and implementing early stopping based on the validation loss to retain the best model weights before overfitting begins.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show first 5 predictions vs actual</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted: </span><span class="si">{</span><span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, Actual: </span><span class="si">{</span><span class="n">true_values</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted: 4.15, Actual: 4.53
Predicted: 4.46, Actual: 3.59
Predicted: 4.43, Actual: 3.52
Predicted: 2.89, Actual: 3.41
Predicted: 2.60, Actual: 3.42
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="conclusions-learnings">
<h1>Conclusions / Learnings<a class="headerlink" href="#conclusions-learnings" title="Link to this heading">#</a></h1>
<div style="border: 2px solid #4CAF50; background-color: #e8f5e9; padding: 15px; border-radius: 10px; margin-top: 10px; margin-bottom: 10px;">
<p>Here are the final conclusions and key learnings drawn from your model‚Äôs training and validation results on the California Housing dataset:</p>
<p><strong> Conclusions </strong></p>
<ol class="arabic simple">
<li><p>Model Generalization is Strong, but Sub-Optimal (R2=0.7873)
The model is a good predictor of house prices, with an R2 score of 0.7873 on the unseen validation data. This means the features can explain nearly 79% of the variance in the target house prices, which is a strong result for a real-world dataset.</p></li>
<li><p>Significant Overfitting Confirmed (Training¬†Loss¬†0.0972 &lt; Validation¬†MSE¬†0.2832)
The large gap between the model‚Äôs best performance on the training data (Loss¬†=0.0972 at Epoch 900) and its performance on the validation data (MSE=0.2832) is the most critical finding. This confirms significant overfitting. The model learned the noise and specific details of the training set extremely well but failed to generalize that performance to new data.</p></li>
<li><p>Training Process is Unstable and Inefficient
The massive spikes and constant high volatility in the training loss curve (e.g., the spike over 2.0 near Epoch 400) demonstrate the training process is highly unstable, likely due to an overly high learning rate. The model constantly overshoots the minimum, forcing it to spend time recovering, which makes the training time inefficient and contributes to the final poor generalization.</p></li>
</ol>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/labs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="lab3.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Understanding Deep Learning : Lab 3</p>
      </div>
    </a>
    <a class="right-next"
       href="lab5.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">LABORATORY TASK 5</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Understanding Deep Learning : Lab 4</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-a-regression-dataset">Linear Regression with a Regression Dataset <br/></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implemention">IMPLEMENTION</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-model">Defining The Model</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusions-learnings">Conclusions / Learnings</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Chris Jallaine
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>