<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Science of Learning: How Neural Networks Find Their Way</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;600;700&family=Inter:wght@300;400;500;600&display=swap');

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --bg-light: #fdf6f0;
            --bg-light-alt: #fff5f5;
            --bg-light-tertiary: #fef0f0;
            --text-primary: #2c1810;
            --text-secondary: #3d2817;
            --text-tertiary: #5a3d2b;
            --accent-primary: #8B4513;
            --accent-secondary: #DC143C;
            --accent-light: #a67c52;
            --border-color: rgba(139, 69, 19, 0.1);
            --card-bg: rgba(255, 255, 255, 0.7);
            --shadow-sm: 0 10px 30px rgba(139, 69, 19, 0.08);
            --shadow-md: 0 15px 50px rgba(139, 69, 19, 0.1);
            --shadow-lg: 0 20px 60px rgba(139, 69, 19, 0.15);
        }

        body.dark-mode {
            --bg-light: #1a1410;
            --bg-light-alt: #241a14;
            --bg-light-tertiary: #2a1f18;
            --text-primary: #f5e6dd;
            --text-secondary: #e8d5c8;
            --text-tertiary: #d4bfb0;
            --card-bg: rgba(40, 30, 25, 0.7);
            --border-color: rgba(220, 20, 60, 0.15);
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: linear-gradient(135deg, var(--bg-light) 0%, var(--bg-light-alt) 50%, var(--bg-light-tertiary) 100%);
            color: var(--text-primary);
            line-height: 1.8;
            font-size: 18px;
            overflow-x: hidden;
            transition: background 0.3s ease, color 0.3s ease;
        }

        .floating-shapes {
            position: fixed;
            width: 100%;
            height: 100%;
            top: 0;
            left: 0;
            z-index: 0;
            pointer-events: none;
            overflow: hidden;
        }

        .shape {
            position: absolute;
            border-radius: 50%;
            opacity: 0.03;
            animation: float 20s infinite ease-in-out;
            transition: opacity 0.3s ease;
        }

        body.dark-mode .shape {
            opacity: 0.05;
        }

        .shape1 {
            width: 400px;
            height: 400px;
            background: var(--accent-primary);
            top: 10%;
            left: -10%;
            animation-delay: 0s;
        }

        .shape2 {
            width: 300px;
            height: 300px;
            background: var(--accent-secondary);
            bottom: 20%;
            right: -5%;
            animation-delay: 5s;
        }

        .shape3 {
            width: 250px;
            height: 250px;
            background: #8B0000;
            top: 50%;
            right: 10%;
            animation-delay: 10s;
        }

        @keyframes float {
            0%, 100% { transform: translate(0, 0) scale(1); }
            33% { transform: translate(30px, -50px) scale(1.1); }
            66% { transform: translate(-20px, 30px) scale(0.9); }
        }

        .theme-toggle {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 999;
            background: var(--card-bg);
            border: 2px solid var(--border-color);
            border-radius: 50px;
            padding: 10px 15px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 20px;
            display: flex;
            align-items: center;
            justify-content: center;
            backdrop-filter: blur(10px);
        }

        .theme-toggle:hover {
            transform: scale(1.1);
            box-shadow: var(--shadow-sm);
        }

        .toc-container {
            position: fixed;
            left: 20px;
            top: 100px;
            width: 250px;
            max-height: 600px;
            background: var(--card-bg);
            border: 2px solid var(--border-color);
            border-radius: 15px;
            padding: 25px;
            overflow-y: auto;
            z-index: 100;
            backdrop-filter: blur(10px);
            transition: all 0.3s ease;
            box-shadow: var(--shadow-md);
        }

        .toc-container.hidden {
            opacity: 0;
            visibility: hidden;
            transform: translateX(-20px);
        }

        .toc-toggle {
            position: fixed;
            left: 20px;
            top: 20px;
            z-index: 999;
            background: var(--card-bg);
            border: 2px solid var(--border-color);
            border-radius: 50px;
            padding: 10px 15px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 20px;
            display: flex;
            align-items: center;
            justify-content: center;
            backdrop-filter: blur(10px);
        }

        .toc-toggle:hover {
            transform: scale(1.1);
            box-shadow: var(--shadow-sm);
        }

        .toc-title {
            font-family: 'Playfair Display', serif;
            font-size: 0.9em;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 15px;
            color: var(--accent-primary);
        }

        .toc-list {
            list-style: none;
        }

        .toc-item {
            margin: 10px 0;
            font-size: 0.85em;
        }

        .toc-item a {
            color: var(--text-tertiary);
            text-decoration: none;
            transition: all 0.3s ease;
            display: block;
            padding: 5px 10px;
            border-radius: 5px;
        }

        .toc-item a:hover {
            color: var(--accent-secondary);
            background: rgba(220, 20, 60, 0.1);
            padding-left: 15px;
        }

        .toc-item a.active {
            color: var(--accent-secondary);
            font-weight: 600;
            border-left: 3px solid var(--accent-secondary);
            padding-left: 12px;
        }

        .header {
            position: relative;
            background: linear-gradient(135deg, rgba(139, 69, 19, 0.05) 0%, rgba(220, 20, 60, 0.05) 100%);
            padding: 120px 40px 80px 40px;
            text-align: center;
            border-bottom: 2px solid var(--border-color);
            z-index: 1;
            transition: background 0.3s ease;
        }

        .header-image {
            width: 100%;
            max-width: 1200px;
            height: 400px;
            margin: 0 auto 60px auto;
            border-radius: 20px;
            overflow: hidden;
            box-shadow: var(--shadow-lg);
            transition: all 0.4s ease;
        }

        .header-image:hover {
            transform: translateY(-8px);
            box-shadow: 0 25px 70px rgba(139, 69, 19, 0.15);
        }

        .header-image img {
            width: 100%;
            height: 100%;
            object-fit: cover;
            animation: fadeInUp 1s ease;
        }

        .header h1 {
            font-family: 'Playfair Display', serif;
            font-size: 4em;
            background: linear-gradient(135deg, var(--accent-primary) 0%, var(--accent-secondary) 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 30px;
            font-weight: 700;
            letter-spacing: -1px;
            line-height: 1.2;
            animation: fadeInUp 1s ease;
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .header .subtitle {
            font-size: 1.3em;
            color: var(--accent-primary);
            font-weight: 300;
            margin-bottom: 30px;
            opacity: 0.8;
            animation: fadeInUp 1s ease 0.2s backwards;
        }

        .header .meta {
            color: var(--accent-light);
            font-size: 0.9em;
            letter-spacing: 1px;
            font-weight: 500;
            animation: fadeInUp 1s ease 0.4s backwards;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 80px 60px 80px 320px;
            position: relative;
            z-index: 1;
            transition: padding 0.3s ease;
        }

        .content-section {
            margin: 80px 0;
            animation: fadeIn 1s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        h2 {
            font-family: 'Playfair Display', serif;
            font-size: 2.8em;
            background: linear-gradient(135deg, var(--accent-primary) 0%, var(--accent-secondary) 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin: 100px 0 50px 0;
            font-weight: 600;
            letter-spacing: -0.5px;
            position: relative;
            padding-bottom: 20px;
            scroll-margin-top: 100px;
        }

        h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 80px;
            height: 3px;
            background: linear-gradient(90deg, var(--accent-primary) 0%, var(--accent-secondary) 100%);
            border-radius: 3px;
        }

        h3 {
            font-family: 'Playfair Display', serif;
            font-size: 2em;
            color: var(--accent-primary);
            margin: 60px 0 30px 0;
            font-weight: 600;
        }

        p {
            margin: 35px 0;
            text-align: justify;
            color: var(--text-secondary);
            transition: color 0.3s ease;
        }

        .lead {
            font-size: 1.3em;
            line-height: 1.9;
            color: var(--text-tertiary);
            margin: 50px 0;
            padding: 50px;
            background: var(--card-bg);
            border-left: 4px solid var(--accent-primary);
            border-radius: 0 15px 15px 0;
            box-shadow: var(--shadow-md);
            transition: all 0.3s ease;
            letter-spacing: 0.3px;
        }

        .lead:hover {
            transform: translateX(5px);
            box-shadow: 0 15px 40px rgba(139, 69, 19, 0.15);
        }

        .image-full {
            width: 100%;
            margin: 80px 0;
            position: relative;
            transition: all 0.3s ease;
        }

        .image-full img {
            width: 100%;
            height: auto;
            display: block;
            border-radius: 16px;
            box-shadow: 0 8px 24px rgba(139, 69, 19, 0.12);
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .image-full:hover img {
            transform: translateY(-4px);
            box-shadow: 0 16px 40px rgba(139, 69, 19, 0.16);
        }

        .image-caption {
            text-align: center;
            font-style: italic;
            color: var(--accent-primary);
            margin-top: 20px;
            font-size: 0.95em;
            opacity: 0.8;
            transition: opacity 0.3s ease;
        }

        .formula-block {
            background: var(--card-bg);
            border: 2px solid var(--border-color);
            border-radius: 15px;
            padding: 35px;
            margin: 50px 0;
            font-family: 'Courier New', monospace;
            color: var(--text-tertiary);
            font-size: 0.95em;
            line-height: 1.9;
            overflow-x: auto;
            box-shadow: var(--shadow-md);
            transition: all 0.3s ease;
            position: relative;
        }

        .formula-block::before {
            content: '‚àá';
            position: absolute;
            top: 15px;
            right: 20px;
            font-size: 3em;
            color: rgba(139, 69, 19, 0.1);
            font-family: serif;
        }

        .formula-block:hover {
            transform: translateY(-3px);
            box-shadow: 0 15px 40px rgba(139, 69, 19, 0.12);
        }

        .copy-btn {
            position: absolute;
            top: 10px;
            right: 50px;
            background: var(--accent-primary);
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 0.8em;
            transition: all 0.3s ease;
            opacity: 0;
            transform: translateY(-10px);
        }

        .formula-block:hover .copy-btn {
            opacity: 1;
            transform: translateY(0);
        }

        .copy-btn:hover {
            background: var(--accent-secondary);
            transform: scale(1.05);
        }

        .copy-btn.copied {
            background: #4CAF50;
        }

        .highlight {
            background: linear-gradient(135deg, rgba(220, 20, 60, 0.05) 0%, rgba(139, 69, 19, 0.05) 100%);
            border-left: 4px solid var(--accent-secondary);
            padding: 35px;
            margin: 50px 0;
            border-radius: 0 15px 15px 0;
            font-style: italic;
            box-shadow: var(--shadow-md);
            transition: transform 0.3s ease;
        }

        .highlight:hover {
            transform: translateX(5px);
        }

        blockquote {
            border-left: 4px solid var(--accent-primary);
            padding: 30px 30px 30px 40px;
            margin: 60px 0;
            font-style: italic;
            color: var(--text-tertiary);
            font-size: 1.2em;
            background: var(--card-bg);
            border-radius: 0 15px 15px 0;
            box-shadow: var(--shadow-md);
            position: relative;
            transition: all 0.3s ease;
        }

        blockquote:hover {
            transform: translateX(5px);
        }

        blockquote::before {
            content: '"';
            position: absolute;
            top: 10px;
            left: 10px;
            font-size: 4em;
            color: rgba(139, 69, 19, 0.15);
            font-family: 'Playfair Display', serif;
        }

        .algorithm-section {
            margin: 100px 0;
            padding: 60px 0;
            position: relative;
        }

        .algorithm-card {
            background: var(--card-bg);
            border: 2px solid var(--border-color);
            border-radius: 20px;
            padding: 50px;
            margin: 50px 0;
            box-shadow: var(--shadow-md);
            transition: all 0.4s ease;
            position: relative;
            overflow: hidden;
        }

        .algorithm-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: linear-gradient(135deg, rgba(139, 69, 19, 0.03) 0%, rgba(220, 20, 60, 0.03) 100%);
            opacity: 0;
            transition: opacity 0.4s ease;
            pointer-events: none;
        }

        .algorithm-card:hover::before {
            opacity: 1;
        }

        .algorithm-card:hover {
            transform: translateY(-10px);
            box-shadow: 0 25px 70px rgba(139, 69, 19, 0.15);
            border-color: rgba(139, 69, 19, 0.2);
        }

        .divider {
            width: 100px;
            height: 3px;
            background: linear-gradient(90deg, var(--accent-primary) 0%, var(--accent-secondary) 100%);
            margin: 80px auto;
            border-radius: 3px;
            position: relative;
            animation: fadeIn 1s ease;
        }

        .divider::before,
        .divider::after {
            content: '';
            position: absolute;
            width: 8px;
            height: 8px;
            background: var(--accent-secondary);
            border-radius: 50%;
            top: -2.5px;
        }

        .divider::before {
            left: -15px;
        }

        .divider::after {
            right: -15px;
        }

        .references {
            margin-top: 120px;
            padding: 60px;
            background: var(--card-bg);
            border-radius: 20px;
            box-shadow: var(--shadow-md);
            transition: all 0.3s ease;
        }

        .references h3 {
            font-family: 'Playfair Display', serif;
            font-size: 2em;
            margin-bottom: 40px;
            color: var(--accent-primary);
        }

        .references ol {
            margin-left: 0;
            padding-left: 25px;
        }

        .references li {
            margin: 25px 0;
            line-height: 1.7;
            color: var(--text-secondary);
            transition: transform 0.3s ease;
        }

        .references li:hover {
            transform: translateX(5px);
        }

        .references a {
            color: var(--accent-primary);
            text-decoration: none;
            border-bottom: 2px solid rgba(139, 69, 19, 0.2);
            transition: all 0.3s ease;
            padding-bottom: 2px;
        }

        .references a:hover {
            color: var(--accent-secondary);
            border-bottom-color: var(--accent-secondary);
        }

        .scroll-progress {
            position: fixed;
            top: 0;
            left: 0;
            width: 0%;
            height: 4px;
            background: linear-gradient(90deg, var(--accent-primary) 0%, var(--accent-secondary) 100%);
            z-index: 1000;
            transition: width 0.1s ease;
            box-shadow: 0 0 10px rgba(220, 20, 60, 0.5);
        }

        .back-to-top {
            position: fixed;
            bottom: 40px;
            right: 40px;
            width: 60px;
            height: 60px;
            background: linear-gradient(135deg, var(--accent-primary) 0%, var(--accent-secondary) 100%);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 24px;
            cursor: pointer;
            opacity: 0;
            visibility: hidden;
            transition: all 0.3s ease;
            z-index: 1000;
            box-shadow: 0 10px 30px rgba(139, 69, 19, 0.3);
            border: none;
        }

        .back-to-top.visible {
            opacity: 1;
            visibility: visible;
        }

        .back-to-top:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 40px rgba(139, 69, 19, 0.4);
        }

        .tag-container {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin: 30px 0;
            justify-content: center;
        }

        .tag {
            padding: 8px 20px;
            background: rgba(139, 69, 19, 0.1);
            border: 1px solid rgba(139, 69, 19, 0.2);
            border-radius: 25px;
            font-size: 0.85em;
            color: var(--accent-primary);
            transition: all 0.3s ease;
            cursor: default;
        }

        .tag:hover {
            background: rgba(139, 69, 19, 0.15);
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(139, 69, 19, 0.2);
        }

        @media (max-width: 1024px) {
            .toc-container {
                display: none;
            }

            .container {
                padding: 80px 60px;
            }
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 2.5em;
            }
            
            .container {
                padding: 60px 30px;
            }

            h2 {
                font-size: 2em;
            }

            body {
                font-size: 16px;
            }

            .header-image {
                height: 250px;
            }

            .algorithm-card {
                padding: 30px;
            }

            .back-to-top {
                bottom: 20px;
                right: 20px;
                width: 50px;
                height: 50px;
                font-size: 20px;
            }

            .theme-toggle {
                top: 70px;
            }

            .toc-toggle {
                display: none;
            }
        }

        .interactive-demo {
            background: var(--card-bg);
            border: 2px solid var(--border-color);
            border-radius: 20px;
            padding: 40px;
            margin: 50px 0;
            text-align: center;
            box-shadow: var(--shadow-md);
        }

        .loading-animation {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(139, 69, 19, 0.2);
            border-radius: 50%;
            border-top-color: var(--accent-primary);
            animation: spin 1s ease-in-out infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        * {
            transition: background-color 0.3s ease, color 0.3s ease, border-color 0.3s ease;
        }

        ::-webkit-scrollbar {
            width: 10px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-light);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--accent-primary);
            border-radius: 5px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--accent-secondary);
        }
    </style>
</head>
<body>
    <div class="floating-shapes">
        <div class="shape shape1"></div>
        <div class="shape shape2"></div>
        <div class="shape shape3"></div>
    </div>

    <button class="theme-toggle" id="themeToggle" title="Toggle dark mode">üåô</button>
    <button class="toc-toggle" id="tocToggle" title="Toggle table of contents">‚ò∞</button>

    <div class="toc-container" id="tocContainer">
        <div class="toc-title">Contents</div>
        <ul class="toc-list" id="tocList"></ul>
    </div>

    <div class="scroll-progress" id="progress"></div>

    <div class="header">
        <div class="header-image">
            <img src="https://images.unsplash.com/photo-1635070041078-e363dbe005cb?w=1400&q=85&fm=jpg&fit=crop" alt="Neural network visualization">
        </div>
        <h1>The Science of Learning:<br>How Neural Networks Find Their Way</h1>
        <p class="subtitle">A Deep Exploration of Optimization Algorithms in Modern Deep Learning</p>
        <p class="meta">By Chris Jalaline Mugot ‚Ä¢ November 16, 2025 ¬∑ 25 minute read</p>
        <div class="tag-container">
            <span class="tag">Deep Learning</span>
            <span class="tag">Optimization</span>
            <span class="tag">Machine Learning</span>
            <span class="tag">Neural Networks</span>
            <span class="tag">AI Research</span>
        </div>
    </div>

    <div class="container">
        <p class="lead">
            In the intricate world of artificial intelligence, where machines learn to recognize faces, translate languages, and even generate art, there exists a fundamental question that drives everything: How do neural networks actually learn? The answer lies not in the architecture of the networks themselves, but in the mathematical machinery that guides their journey from ignorance to expertise‚Äîoptimization algorithms.
        </p>

        <div class="content-section">
            <h2>The Foundation of Learning</h2>
            
            <p>
                Every neural network begins its life in a state of profound ignorance. Its weights are initialized randomly, its predictions are essentially guesses, and its understanding of the world is nonexistent. Yet through the application of optimization algorithms, these same networks can learn to perform tasks that once seemed impossible for machines. This transformation is not magic‚Äîit is mathematics, carefully applied through a process we call optimization.
            </p>

            <p>
                At its core, training a neural network is an optimization problem. We have a loss function, a mathematical measure of how wrong the network's predictions are, and we want to find the configuration of weights that minimizes this loss. If we could visualize this problem, we would see a landscape‚Äîsometimes called the loss landscape‚Äîwith peaks, valleys, plateaus, and ravines. Somewhere in this landscape lies a valley representing low loss and good performance. The optimization algorithm is our guide through this landscape, determining the path we take and whether we ever reach that valley.
            </p>

            <div class="image-full">
                <img src="https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=1400&q=85&fm=jpg&fit=crop" alt="Complex data visualization">
                <p class="image-caption">The loss landscape of a neural network: a complex, high-dimensional terrain that optimization algorithms must navigate</p>
            </div>

            <p>
                The challenge is formidable. Modern neural networks often have millions or billions of parameters, creating a loss landscape that exists in unimaginably high-dimensional space. This landscape is non-convex, meaning it contains countless local minima where an optimizer might get stuck, thinking it has found the best solution when better solutions exist elsewhere. It contains saddle points‚Äîlocations where the gradient is zero but which are neither maxima nor minima‚Äîthat can trap optimization algorithms. And it contains vast plateaus where the gradient is nearly zero, making it difficult to determine which direction to move.
            </p>

            <p>
                The algorithms we use to navigate this landscape have evolved considerably over the decades, each generation learning from the limitations of its predecessors. What began as simple gradient descent has blossomed into a sophisticated family of adaptive algorithms that can handle the immense complexity of modern deep learning. Understanding these algorithms‚Äîtheir mechanisms, their strengths, their weaknesses‚Äîis essential for anyone seeking to master the art of training neural networks.
            </p>
        </div>

        <div class="divider"></div>

        <div class="algorithm-section">
            <h2>Gradient Descent: The Bedrock</h2>
            
            <div class="algorithm-card">
                <p>
                    The story of optimization in deep learning begins with gradient descent, an algorithm so fundamental that understanding it is prerequisite to understanding everything that follows. The intuition behind gradient descent is elegantly simple: if you want to descend a mountain, you should take steps in the direction of steepest descent. In mathematical terms, this direction is given by the negative gradient of the loss function with respect to the model's parameters.
                </p>

                <div class="formula-block">
Œ∏(t+1) = Œ∏(t) - Œ∑ ¬∑ ‚àáJ(Œ∏(t))

Where:
Œ∏ represents the model parameters (weights and biases)
Œ∑ is the learning rate, controlling step size
‚àáJ(Œ∏) is the gradient of the loss function J with respect to Œ∏
t indexes the iteration number
                    <button class="copy-btn" onclick="copyToClipboard(this)">Copy</button>
                </div>

                <p>
                    In its pure form‚Äîwhat we call batch gradient descent or simply gradient descent‚Äîthe algorithm computes this gradient using the entire training dataset. For each iteration, it evaluates the loss function across all training examples, computes the gradient, and updates the parameters. This approach has the virtue of stability: because we're using all available data, our gradient estimate is accurate, and our path down the loss landscape is smooth and predictable.
                </p>
            </div>

            <div class="image-full">
                <img src="https://images.unsplash.com/photo-1518186285589-2f7649de83e0?w=1400&q=85&fm=jpg&fit=crop" alt="Flowing water">
                <p class="image-caption">Gradient descent flows smoothly toward minima, like water finding its level</p>
            </div>

            <p>
                But this stability comes at a devastating cost. Modern datasets routinely contain millions of examples. ImageNet, a standard benchmark in computer vision, has over 14 million images. Large language models train on datasets containing hundreds of billions of tokens. Computing the exact gradient across such datasets for every single parameter update is computationally infeasible. A single iteration of batch gradient descent on ImageNet would require processing all 14 million images just to take one step in parameter space. At this rate, training would take years, even on the most powerful hardware.
            </p>

            <p>
                Beyond computational concerns, batch gradient descent suffers from a more subtle problem. Because it always takes the exact gradient direction, it can become trapped in sharp, narrow minima. Research has shown that such minima, while representing low training loss, often generalize poorly to new data. The network has found a very specific solution that works well for the training set but fails to capture the underlying patterns that would allow it to perform well on unseen examples.
            </p>

            <p>
                These limitations led researchers to explore alternatives that could maintain the theoretical elegance of gradient descent while addressing its practical shortcomings. The answer came from embracing randomness rather than fighting it.
            </p>
        </div>

        <div class="algorithm-section">
            <h2>Stochastic Gradient Descent: Embracing Noise</h2>
            
            <div class="algorithm-card">
                <p>
                    Stochastic Gradient Descent, often abbreviated as SGD, represents a paradigm shift in how we think about optimization. Rather than computing the exact gradient using all training data, SGD approximates the gradient using just a single training example‚Äîor more commonly in practice, a small subset called a mini-batch. This might seem like a step backward, trading accuracy for speed, but the implications are far more profound than simple computational savings.
                </p>

                <div class="formula-block">
For each mini-batch B of size m:

g(t) = (1/m) ¬∑ Œ£ ‚àáJ(Œ∏(t); xi, yi)  for (xi, yi) in B

Œ∏(t+1) = Œ∏(t) - Œ∑ ¬∑ g(t)

Where:
B is a randomly sampled mini-batch from the training set
m is the mini-batch size (typically 32, 64, 128, or 256)
g(t) is the stochastic gradient estimate
                    <button class="copy-btn" onclick="copyToClipboard(this)">Copy</button>
                </div>

                <p>
                    The gradient computed from a mini-batch is noisy‚Äîit's an imperfect estimate of the true gradient we would get from the full dataset. This noise means that SGD's path through parameter space is not the smooth trajectory of batch gradient descent but rather a chaotic, jittering journey. At first glance, this seems like a flaw. But this noise is not a bug; it's a feature, and a crucial one at that.
                </p>
            </div>

            <div class="image-full">
                <img src="https://images.unsplash.com/photo-1635070041078-e363dbe005cb?w=1400&q=85&fm=jpg&fit=crop" alt="Neural network nodes">
                <p class="image-caption">Stochastic processes in neural networks create pathways to robust solutions</p>
            </div>

            <p>
                The noise in SGD serves multiple beneficial purposes. First, it allows the optimizer to escape from sharp, narrow minima. When batch gradient descent encounters such a minimum, it settles there, satisfied with having found a location where the gradient is zero. But SGD's noisy gradients can kick it out of such minima, forcing it to continue exploring until it finds a wider, flatter basin. These flat minima have been shown to correlate strongly with better generalization‚Äînetworks that find flat minima tend to perform better on new, unseen data.
            </p>

            <p>
                Second, the stochasticity acts as a form of implicit regularization. The noise introduced during training prevents the network from memorizing the training data too precisely. Instead, it must learn robust features that remain useful despite the noise, leading to representations that generalize better. This effect is so powerful that SGD-trained networks often outperform networks trained with more sophisticated optimizers, particularly when generalization is critical.
            </p>

            <p>
                Third, the computational efficiency of SGD enables training on massive datasets. By updating parameters after seeing just a small mini-batch rather than the entire dataset, SGD can make hundreds or thousands of updates in the time batch gradient descent makes one. This means that even though each SGD update is noisier and less accurate, the sheer number of updates compensates, often leading to faster overall convergence to a good solution.
            </p>

            <blockquote>
                "The random noise in stochastic gradient descent is not an obstacle to overcome, but a tool to exploit. It transforms optimization from a deterministic search into a stochastic exploration, and in doing so, discovers solutions that deterministic methods cannot reach." ‚Äî L√©on Bottou, Microsoft Research
            </blockquote>
        </div>

        <div class="algorithm-section">
            <h2>Momentum: Building Speed in Consistent Directions</h2>
            
            <div class="algorithm-card">
                <p>
                    While SGD's stochasticity provides valuable benefits, it also creates problems. The noisy gradients can cause the optimizer to oscillate wildly, particularly in directions where the loss landscape is steep but narrow. Imagine trying to navigate a ravine: you want to make progress along the ravine, but the steep walls on either side cause you to bounce back and forth, making little forward progress. This is where momentum comes in, adding a concept borrowed from physics to smooth out these oscillations while accelerating progress in consistent directions.
                </p>

                <div class="formula-block">
v(t) = Œ≤ ¬∑ v(t-1) + Œ∑ ¬∑ g(t)

Œ∏(t+1) = Œ∏(t) - v(t)

Where:
v(t) is the velocity vector (accumulated gradient)
Œ≤ is the momentum coefficient (typically 0.9 or 0.99)
g(t) is the current gradient
Œ∑ is the learning rate
                    <button class="copy-btn" onclick="copyToClipboard(this)">Copy</button>
                </div>

                <p>
                    Momentum maintains a running average of past gradients, stored in a velocity vector. At each step, instead of moving directly in the direction of the current gradient, we move in a direction that combines the current gradient with this velocity. If gradients consistently point in a particular direction, the velocity builds up, and we accelerate in that direction. If gradients oscillate‚Äîpointing one way then another‚Äîthese oscillations cancel out in the velocity, and we don't waste time moving back and forth.
                </p>
            </div>

            <div class="image-full">
                <img src="https://images.unsplash.com/photo-1518186285589-2f7649de83e0?w=1400&q=85&fm=jpg&fit=crop" alt="Motion blur">
                <p class="image-caption">Momentum accelerates optimization, building velocity in directions of consistent descent</p>
            </div>

            <p>
                The benefits of momentum are substantial. In ravine-like regions of the loss landscape‚Äîcommon in neural network optimization‚Äîmomentum dramatically accelerates progress. Without momentum, the optimizer wastes most of its time oscillating across the ravine rather than moving along it. With momentum, the cross-ravine oscillations cancel out while the along-ravine motion accumulates, leading to much faster progress. Empirically, momentum can reduce training time by factors of two or more compared to plain SGD.
            </p>

            <p>
                Momentum also helps navigate flat regions, or plateaus, in the loss landscape. When the gradient is very small, plain SGD makes tiny steps and can get stuck. But with momentum, the velocity accumulated from before the plateau carries the optimizer forward, helping it maintain progress even when the current gradient provides little information.
            </p>
        </div>

        <div class="algorithm-section">
            <h2>AdaGrad: Individual Learning Rates</h2>
            
            <div class="algorithm-card">
                <p>
                    All the optimizers we've discussed so far use a single global learning rate that applies equally to all parameters. But this seems inefficient‚Äîdifferent parameters may need different learning rates. Parameters associated with frequently occurring features may need smaller updates, having already received many gradient signals, while parameters for rare features need larger updates to learn from their limited training signal. AdaGrad, introduced by Duchi, Hazan, and Singer in 2011, was one of the first algorithms to adapt the learning rate individually for each parameter.
                </p>

                <div class="formula-block">
g(t) = ‚àáJ(Œ∏(t))

G(t) = G(t-1) + g(t) ‚äô g(t)

Œ∏(t+1) = Œ∏(t) - (Œ∑ / ‚àö(G(t) + Œµ)) ‚äô g(t)

Where:
G(t) accumulates the sum of squared gradients for each parameter
‚äô denotes element-wise multiplication
Œµ is a small constant (typically 10^-8) for numerical stability
                    <button class="copy-btn" onclick="copyToClipboard(this)">Copy</button>
                </div>

                <p>
                    The key insight of AdaGrad is to divide the learning rate by the square root of the accumulated squared gradients. Parameters that have received large gradients in the past will have large values in G(t), leading to smaller effective learning rates. Parameters that have received small gradients will have small values in G(t), maintaining larger effective learning rates. This automatic adaptation means that frequently updated parameters take smaller steps (they've already learned a lot) while infrequently updated parameters take larger steps (they need to catch up).
                </p>
            </div>

            <div class="image-full">
                <img src="https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=1400&q=85&fm=jpg&fit=crop" alt="Data streams">
                <p class="image-caption">Adaptive algorithms adjust their behavior based on the accumulated history of optimization</p>
            </div>

            <p>
                AdaGrad proved particularly effective for sparse data‚Äîsituations where most features are zero most of the time. In natural language processing, for instance, most words in a vocabulary don't appear in any given sentence. AdaGrad ensures that when a rare word does appear, the parameters associated with it can be updated substantially, despite having received few updates overall. This made AdaGrad popular in early deep learning applications for text.
            </p>

            <p>
                However, AdaGrad has a critical flaw: the accumulated squared gradients in G(t) only grow, never shrink. As training progresses, G(t) becomes larger and larger, which means the effective learning rate becomes smaller and smaller. Eventually, the learning rate becomes so small that the optimizer effectively stops learning entirely, even if it hasn't yet reached a good solution. This premature stopping of learning makes AdaGrad unsuitable for training deep neural networks, which often require many passes through the data.
            </p>
        </div>

        <div class="algorithm-section">
            <h2>RMSProp: Forgetting the Distant Past</h2>
            
            <div class="algorithm-card">
                <p>
                    RMSProp, developed by Geoffrey Hinton and presented in his Coursera course on neural networks, directly addresses AdaGrad's problem of monotonically decreasing learning rates. Instead of accumulating all past squared gradients, RMSProp maintains an exponentially decaying average, giving more weight to recent gradients while allowing old gradients to be forgotten. This simple but crucial modification allows the learning rate to both increase and decrease over time, adapting to the current local characteristics of the loss landscape rather than being permanently influenced by gradients from early in training.
                </p>

                <div class="formula-block">
E[g¬≤](t) = Œ≥ ¬∑ E[g¬≤](t-1) + (1 - Œ≥) ¬∑ g(t)¬≤

Œ∏(t+1) = Œ∏(t) - (Œ∑ / ‚àö(E[g¬≤](t) + Œµ)) ¬∑ g(t)

Where:
E[g¬≤](t) is the exponentially weighted average of squared gradients
Œ≥ is the decay rate (typically 0.9 or 0.99)
Œ∑ is the learning rate (typically 0.001)
                    <button class="copy-btn" onclick="copyToClipboard(this)">Copy</button>
                </div>

                <p>
                    The decay rate Œ≥ controls how quickly the influence of old gradients fades. With Œ≥ = 0.9, the effective window of gradients being averaged is about ten steps; with Œ≥ = 0.99, it's about a hundred steps. This allows RMSProp to adapt to changes in the loss landscape. If the optimizer enters a new region where the gradients have different characteristics, those old gradients from the previous region will quickly fade from the running average, and the learning rate will adapt to the new conditions.
                </p>
            </div>

            <p>
                RMSProp proved particularly effective for training recurrent neural networks, which often exhibit challenging optimization dynamics. The error signals in RNNs can vary dramatically in magnitude depending on the length of sequences being processed, and the ability of RMSProp to adapt quickly to these changing conditions made it the optimizer of choice for many early RNN applications.
            </p>
        </div>

        <div class="algorithm-section">
            <h2>Adam: The Modern Standard</h2>
            
            <div class="algorithm-card">
                <p>
                    Adam, short for Adaptive Moment Estimation and introduced by Kingma and Ba in 2014, synthesizes the best ideas from momentum and RMSProp while adding an important correction mechanism. It has become the default choice for many deep learning practitioners, and for good reason‚Äîit combines computational efficiency, minimal hyperparameter tuning requirements, and strong performance across a wide variety of problems.
                </p>

                <div class="formula-block">
m(t) = Œ≤‚ÇÅ ¬∑ m(t-1) + (1 - Œ≤‚ÇÅ) ¬∑ g(t)
v(t) = Œ≤‚ÇÇ ¬∑ v(t-1) + (1 - Œ≤‚ÇÇ) ¬∑ g(t)¬≤

mÃÇ(t) = m(t) / (1 - Œ≤‚ÇÅ^t)
vÃÇ(t) = v(t) / (1 - Œ≤‚ÇÇ^t)

Œ∏(t+1) = Œ∏(t) - Œ∑ ¬∑ mÃÇ(t) / (‚àö(vÃÇ(t)) + Œµ)

Where:
m(t) is the first moment estimate (mean of gradients)
v(t) is the second moment estimate (uncentered variance)
Œ≤‚ÇÅ is typically 0.9, Œ≤‚ÇÇ is typically 0.999
Œ∑ is the learning rate, typically 0.001 or 0.0001
The hat notation (mÃÇ, vÃÇ) indicates bias-corrected estimates
                    <button class="copy-btn" onclick="copyToClipboard(this)">Copy</button>
                </div>

                <p>
                    Adam maintains two running averages: m(t), an exponentially decaying average of past gradients (like momentum), and v(t), an exponentially decaying average of past squared gradients (like RMSProp). The first moment m(t) helps accelerate optimization in consistent directions and dampen oscillations, while the second moment v(t) adapts the learning rate for each parameter based on the history of gradient magnitudes.
                </p>
            </div>

            <div class="image-full">
                <img src="https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=1400&q=85&fm=jpg&fit=crop" alt="Flowing abstract data">
                <p class="image-caption">Adam optimizer combines multiple adaptation strategies for robust, efficient learning</p>
            </div>

            <p>
                The bias correction mechanism (the hat notation mÃÇ and vÃÇ) is Adam's subtle but important innovation. When we initialize m and v to zero, their early values are biased toward zero‚Äîthe exponential averages need time to "warm up" before they accurately reflect the true statistics of the gradients. Adam corrects for this initialization bias by dividing by (1 - Œ≤^t), which compensates for the fact that we started at zero. In early iterations, when t is small, this correction is substantial; as t grows, Œ≤^t approaches zero, and the correction term approaches one, having minimal effect.
            </p>

            <p>
                The combination of these elements makes Adam remarkably robust. The momentum component helps it build up speed in consistent directions and navigate plateaus. The adaptive learning rates help it handle parameters that learn at different rates. The bias correction ensures that early updates, when we have the least information, are handled appropriately. And all of this comes with relatively little tuning required‚Äîthe default hyperparameters work well for a very wide range of problems.
            </p>
        </div>

        <div class="algorithm-section">
            <h2>AdamW: Correcting Weight Decay</h2>
            
            <div class="algorithm-card">
                <p>
                    Weight decay is a form of regularization where we add a penalty term to the loss function proportional to the squared magnitude of the weights. This encourages the network to keep weights small, which can improve generalization. In standard SGD, weight decay is straightforward, but research by Loshchilov and Hutter in 2017 revealed that Adam and other adaptive optimizers don't implement weight decay correctly when it's added to the loss function‚Äîthe interaction between adaptive learning rates and weight decay creates unintended behavior.
                </p>

                <div class="formula-block">
Standard Adam with L2 regularization (incorrect):
Loss = J(Œ∏) + (Œª/2) ¬∑ ||Œ∏||¬≤

AdamW (correct weight decay):
Œ∏(t+1) = Œ∏(t) - Œ∑ ¬∑ (mÃÇ(t) / (‚àö(vÃÇ(t)) + Œµ) + Œª ¬∑ Œ∏(t))

Where:
Œª is the weight decay coefficient
The weight decay is applied directly to parameters, not through gradient
                    <button class="copy-btn" onclick="copyToClipboard(this)">Copy</button>
                </div>

                <p>
                    AdamW decouples weight decay from the gradient-based update by applying it directly to the parameters after the adaptive update. This subtle change has significant effects. With proper weight decay implementation, AdamW achieves generalization performance much closer to SGD with momentum while maintaining Adam's fast convergence and minimal tuning requirements. For many practitioners, AdamW has become the default choice, replacing vanilla Adam for most applications.
                </p>
            </div>
        </div>

        <div class="algorithm-section">
            <h2>Advanced Optimizers: Pushing the Boundaries</h2>
            
            <div class="algorithm-card">
                <h3>Nadam: Nesterov-Accelerated Adam</h3>
                <p>
                    Nadam combines Adam with Nesterov acceleration, incorporating a lookahead mechanism that makes the optimizer slightly more responsive to changes in the loss landscape. The lookahead mechanism makes Nadam often converge slightly faster than Adam, though the difference is typically modest.
                </p>

                <h3>AMSGrad: Theoretical Guarantees</h3>
                <p>
                    AMSGrad addresses cases where Adam can fail to converge by maintaining the maximum of past squared gradient averages rather than just the current exponential average. This ensures the effective learning rate can only decrease over time, providing theoretical convergence guarantees that vanilla Adam lacks.
                </p>

                <h3>LAMB and LARS: Scaling to Massive Batches</h3>
                <p>
                    These algorithms adapt learning rates per layer rather than per parameter, enabling training with batch sizes of 32,000 or more. This has enabled dramatic reductions in training time for large models‚ÄîBERT can be trained to full accuracy in 76 minutes using LAMB with enormous batches.
                </p>
            </div>

            <div class="image-full">
                <img src="https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=1400&q=85&fm=jpg&fit=crop" alt="Abstract convergence visualization">
                <p class="image-caption">Modern optimization algorithms seek to balance fast convergence with robust generalization</p>
            </div>
        </div>

        <div class="algorithm-section">
            <h2>Choosing an Optimizer: Practical Guidance</h2>
            
            <div class="algorithm-card">
                <p>
                    With such a wealth of optimization algorithms available, choosing the right one for a particular problem can seem daunting. While there's no single best optimizer for all situations, some general principles can guide the decision.
                </p>

                <p>
                    For most practitioners starting a new project, <strong>Adam or AdamW</strong> is the recommended starting point. These optimizers work well across a broad range of architectures and domains with minimal hyperparameter tuning. The default settings are remarkably robust, making Adam an excellent choice when you want to focus on architecture and data rather than optimization details.
                </p>

                <p>
                    However, for <strong>computer vision tasks</strong>, particularly image classification with convolutional networks, SGD with momentum often achieves superior final performance. The generalization advantage of SGD becomes most apparent when training for many epochs on relatively clean, curated datasets like ImageNet. The trade-off is that SGD requires more careful tuning of the learning rate and learning rate schedule.
                </p>

                <p>
                    For <strong>natural language processing</strong> and particularly for training large language models, Adam and its variants reign supreme. The sparse gradient structure common in NLP tasks plays to Adam's strengths, and the reduced need for learning rate tuning is valuable when training runs can take days or weeks. AdamW is particularly popular for transformer models.
                </p>

                <p>
                    For <strong>recurrent neural networks</strong>, RMSProp and Adam both work well. RNNs present unique optimization challenges due to temporal dependencies and varying sequence lengths, and adaptive learning rates help navigate these difficulties.
                </p>
            </div>

            <div class="image-full">
                <img src="https://images.unsplash.com/photo-1550745165-9bc0b252726f?w=1400&q=85&fm=jpg&fit=crop" alt="Decision paths">
                <p class="image-caption">Choosing the right optimizer requires understanding the trade-offs between convergence speed, generalization, and computational cost</p>
            </div>
        </div>

        <div class="divider"></div>

        <div class="content-section">
            <h2>The Future of Optimization</h2>
            
            <p>
                As neural networks grow ever larger and tackle increasingly complex tasks, optimization algorithms must evolve to meet new challenges. Several trends are shaping the future of optimization research.
            </p>

            <p>
                First, there's growing interest in <strong>learned optimizers</strong>‚Äîusing machine learning to learn optimization algorithms themselves. Rather than hand-crafting update rules, we could train a neural network to function as an optimizer, learning from experience across many training runs how to update parameters most effectively.
            </p>

            <p>
                Second, as models scale to billions or trillions of parameters, <strong>memory-efficient optimization</strong> becomes increasingly critical. Standard Adam requires storing two additional parameters for each model parameter. At massive scale, this memory overhead becomes prohibitive.
            </p>

            <div class="image-full">
                <img src="https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=1400&q=85&fm=jpg&fit=crop" alt="Futuristic technology">
                <p class="image-caption">The future of optimization lies in algorithms that can scale to ever-larger models while maintaining efficiency</p>
            </div>

            <p>
                Third, there's renewed interest in understanding <strong>why certain optimizers generalize better</strong> than others. The connection between optimization and generalization‚Äîbetween finding low loss on training data and achieving good performance on new data‚Äîremains incompletely understood. Answering these questions could lead to optimizers specifically designed to find solutions that generalize well.
            </p>

            <p>
                Finally, there's growing appreciation for the role of stochasticity beyond simple mini-batch sampling. Techniques like adding noise to gradients, using different optimizers for different parts of the network, or periodically perturbing parameters all introduce additional randomness that can improve both optimization and generalization.
            </p>
        </div>

        <div class="divider"></div>

        <div class="content-section">
            <h2>Conclusion</h2>
            
            <p>
                Optimization algorithms are the hidden engine of deep learning, the mathematical machinery that transforms randomly initialized neural networks into powerful systems capable of understanding language, recognizing images, and solving complex problems. From the elegant simplicity of gradient descent to the sophisticated adaptivity of modern algorithms like Adam and beyond, each optimizer represents a different philosophy about how to navigate the complex, high-dimensional loss landscapes of neural networks.
            </p>

            <p>
                The journey from batch gradient descent to today's state-of-the-art optimizers reflects our growing understanding of what makes neural network training succeed or fail. We've learned that exact gradients aren't always better than noisy ones, that treating all parameters the same is often suboptimal, and that the path we take through parameter space matters as much as the destination we reach.
            </p>

            <p>
                Yet despite decades of research and hundreds of proposed algorithms, we still don't have a single optimizer that's best for all problems. SGD with momentum remains the gold standard for computer vision; Adam dominates natural language processing; specialized algorithms like LAMB enable training at unprecedented scale. This diversity isn't a failure of the field but a reflection of the rich variety of optimization challenges that different neural network architectures and application domains present.
            </p>

            <p>
                For practitioners, the key lesson is pragmatic: start with proven algorithms like Adam or SGD with momentum, understand their strengths and weaknesses, and be prepared to experiment. The best optimizer for your specific problem is ultimately an empirical question, answerable only through careful experimentation. But armed with an understanding of how these algorithms work and why they make the choices they do, you're well-equipped to make informed decisions and troubleshoot problems when training doesn't proceed as expected.
            </p>

            <p>
                As neural networks continue to grow in scale and capability, optimization algorithms will evolve alongside them. New challenges will emerge, requiring new solutions. But the fundamental principles‚Äîfollowing gradients, adapting to the local landscape, balancing exploration and exploitation‚Äîwill remain. The science of teaching neural networks to learn is itself a learning process, and we're still in the early chapters of that story.
            </p>
        </div>

        <div class="divider"></div>

        <div class="references">
            <h3>References & Further Reading</h3>
            <ol>
                <li>Ruder, S. (2016). "An overview of gradient descent optimization algorithms." <em>arXiv preprint arXiv:1609.04747</em>. <a href="https://arxiv.org/abs/1609.04747" target="_blank">https://arxiv.org/abs/1609.04747</a></li>
                
                <li>Kingma, D. P., & Ba, J. (2014). "Adam: A method for stochastic optimization." <em>arXiv preprint arXiv:1412.6980</em>. <a href="https://arxiv.org/abs/1412.6980" target="_blank">https://arxiv.org/abs/1412.6980</a></li>
                
                <li>Loshchilov, I., & Hutter, F. (2017). "Decoupled weight decay regularization." <em>arXiv preprint arXiv:1711.05101</em>. <a href="https://arxiv.org/abs/1711.05101" target="_blank">https://arxiv.org/abs/1711.05101</a></li>
                
                <li>Bottou, L., Curtis, F. E., & Nocedal, J. (2018). "Optimization methods for large-scale machine learning." <em>SIAM Review, 60</em>(2), 223-311. <a href="https://doi.org/10.1137/16M1080173" target="_blank">https://doi.org/10.1137/16M1080173</a></li>
                
                <li>Duchi, J., Hazan, E., & Singer, Y. (2011). "Adaptive subgradient methods for online learning and stochastic optimization." <em>Journal of Machine Learning Research, 12</em>(7), 2121-2159.</li>
                
                <li>Tieleman, T., & Hinton, G. (2012). "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude." <em>COURSERA: Neural networks for machine learning, 4</em>(2), 26-31.</li>
                
                <li>Keskar, N. S., Mudigere, D., Nocedal, J., Smelyanskiy, M., & Tang, P. T. P. (2016). "On large-batch training for deep learning: Generalization gap and sharp minima." <em>arXiv preprint arXiv:1609.04836</em>. <a href="https://arxiv.org/abs/1609.04836" target="_blank">https://arxiv.org/abs/1609.04836</a></li>
                
                <li>You, Y., Gitman, I., & Ginsburg, B. (2017). "Large batch training of convolutional networks." <em>arXiv preprint arXiv:1708.03888</em>. <a href="https://arxiv.org/abs/1708.03888" target="_blank">https://arxiv.org/abs/1708.03888</a></li>
                
                <li>You, Y., Li, J., Reddi, S., Hseu, J., Kumar, S., Bhojanapalli, S., ... & Hsieh, C. J. (2019). "Large batch optimization for deep learning: Training BERT in 76 minutes." <em>arXiv preprint arXiv:1904.00962</em>. <a href="https://arxiv.org/abs/1904.00962" target="_blank">https://arxiv.org/abs/1904.00962</a></li>
                
                <li>Reddi, S. J., Kale, S., & Kumar, S. (2019). "On the convergence of adam and beyond." <em>arXiv preprint arXiv:1904.09237</em>. <a href="https://arxiv.org/abs/1904.09237" target="_blank">https://arxiv.org/abs/1904.09237</a></li>
            </ol>
        </div>
    </div>

    <button class="back-to-top" id="backToTop">‚Üë</button>

    <script>
        const themeToggle = document.getElementById('themeToggle');
        const htmlElement = document.documentElement;
        const body = document.body;

        const currentTheme = localStorage.getItem('theme') || 'light';
        if (currentTheme === 'dark') {
            body.classList.add('dark-mode');
            themeToggle.textContent = '‚òÄÔ∏è';
        }

        themeToggle.addEventListener('click', function() {
            body.classList.toggle('dark-mode');
            const theme = body.classList.contains('dark-mode') ? 'dark' : 'light';
            localStorage.setItem('theme', theme);
            themeToggle.textContent = theme === 'dark' ? '‚òÄÔ∏è' : 'üåô';
        });

        const tocList = document.getElementById('tocList');
        const tocContainer = document.getElementById('tocContainer');
        const tocToggle = document.getElementById('tocToggle');

        function generateTOC() {
            const headings = document.querySelectorAll('h2');
            headings.forEach((heading, index) => {
                const id = `heading-${index}`;
                heading.id = id;

                const li = document.createElement('li');
                li.className = 'toc-item';
                const a = document.createElement('a');
                a.href = `#${id}`;
                a.textContent = heading.textContent;
                li.appendChild(a);
                tocList.appendChild(li);
            });
        }

        tocToggle.addEventListener('click', function() {
            tocContainer.classList.toggle('hidden');
        });

        window.addEventListener('scroll', function() {
            const headings = document.querySelectorAll('h2');
            let current = '';

            headings.forEach(heading => {
                const rect = heading.getBoundingClientRect();
                if (rect.top < 200) {
                    current = heading.id;
                }
            });

            document.querySelectorAll('.toc-item a').forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === `#${current}`) {
                    link.classList.add('active');
                }
            });
        });

        generateTOC();

        window.addEventListener('scroll', function() {
            const winScroll = document.body.scrollTop || document.documentElement.scrollTop;
            const height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
            const scrolled = (winScroll / height) * 100;
            document.getElementById('progress').style.width = scrolled + '%';
            
            const backToTop = document.getElementById('backToTop');
            if (winScroll > 300) {
                backToTop.classList.add('visible');
            } else {
                backToTop.classList.remove('visible');
            }
        });

        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        function copyToClipboard(button) {
            const formulaBlock = button.parentElement;
            const text = formulaBlock.innerText.replace('Copy', '').trim();
            
            navigator.clipboard.writeText(text).then(() => {
                const originalText = button.textContent;
                button.textContent = '‚úì Copied!';
                button.classList.add('copied');
                
                setTimeout(() => {
                    button.textContent = originalText;
                    button.classList.remove('copied');
                }, 2000);
            });
        }

        const images = document.querySelectorAll('.image-full img');
        images.forEach(img => {
            img.addEventListener('load', function() {
                this.style.opacity = '0';
                setTimeout(() => {
                    this.style.transition = 'opacity 0.5s ease';
                    this.style.opacity = '1';
                }, 100);
            });
        });
    </script>
</body>
</html>