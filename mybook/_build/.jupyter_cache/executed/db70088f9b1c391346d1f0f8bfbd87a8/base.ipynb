{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e726bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4ddb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Inputs and target (from Task 2)\n",
    "# -----------------------------\n",
    "\n",
    "x = np.array([1, 0, 1])   # input vector\n",
    "y = np.array([1])         # target output\n",
    "lr = 0.001                # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e08eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Initialize weights and biases (from Task 2)\n",
    "# -----------------------------\n",
    "# Hidden layer weights (3 inputs -> 2 hidden neurons)\n",
    "\n",
    "W_hidden = np.array([\n",
    "    [0.2, -0.3],   # weights for input x1\n",
    "    [0.4,  0.1],   # weights for input x2\n",
    "    [-0.5, 0.2]    # weights for input x3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71cc98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biases for hidden neurons\n",
    "b_hidden = np.array([-0.4, 0.2])\n",
    "\n",
    "# Output layer weights (2 hidden -> 1 output neuron)\n",
    "W_output = np.array([[-0.3], [-0.2]])\n",
    "\n",
    "# Bias for output neuron\n",
    "b_output = np.array([0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f256d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Activation functions\n",
    "# -----------------------------\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_derivative(z):\n",
    "    return np.where(z > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381c2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Forward pass\n",
    "# -----------------------------\n",
    "\n",
    "# Hidden layer computation\n",
    "Z_hidden = np.dot(x, W_hidden) + b_hidden   # weighted sum\n",
    "H = relu(Z_hidden)                         # apply ReLU\n",
    "\n",
    "# Output layer computation\n",
    "Z_output = np.dot(H, W_output) + b_output\n",
    "y_hat = relu(Z_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e51586d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass:\n",
      "Z_hidden = [-0.7  0.1]\n",
      "H (hidden activations) = [0.  0.1]\n",
      "Z_output = [0.08]\n",
      "y_hat (prediction) = [0.08]\n"
     ]
    }
   ],
   "source": [
    "print(\"Forward Pass:\")\n",
    "print(\"Z_hidden =\", Z_hidden)\n",
    "print(\"H (hidden activations) =\", H)\n",
    "print(\"Z_output =\", Z_output)\n",
    "print(\"y_hat (prediction) =\", y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "053996fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.8464\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Compute loss (Mean Squared Error)\n",
    "# -----------------------------\n",
    "loss = np.mean((y - y_hat) ** 2)\n",
    "print(\"Loss =\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fcd1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Backward pass\n",
    "# -----------------------------\n",
    "# Derivative of loss w.r.t y_hat (MSE derivative)\n",
    "dL_dyhat = 2 * (y_hat - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff46a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative through ReLU at output\n",
    "dyhat_dZout = relu_derivative(Z_output)\n",
    "dL_dZout = dL_dyhat * dyhat_dZout\n",
    "\n",
    "# Gradients for output weights and bias\n",
    "dL_dWout = H.reshape(-1,1) @ dL_dZout.reshape(1,-1)   # outer product\n",
    "dL_dbout = dL_dZout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "212bf41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients for output weights and bias\n",
    "dL_dWout = H.reshape(-1,1) @ dL_dZout.reshape(1,-1)   # outer product\n",
    "dL_dbout = dL_dZout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a21c617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop to hidden layer\n",
    "dL_dH = dL_dZout @ W_output.T\n",
    "dH_dZhidden = relu_derivative(Z_hidden)\n",
    "dL_dZhidden = dL_dH * dH_dZhidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "833bd228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients for hidden weights and biases\n",
    "dL_dWhidden = x.reshape(-1,1) @ dL_dZhidden.reshape(1,-1)\n",
    "dL_dbhidden = dL_dZhidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ca9d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backward Pass:\n",
      "dL_dWout = \n",
      " [[ 0.   ]\n",
      " [-0.184]]\n",
      "dL_dbout = \n",
      " [-1.84]\n",
      "dL_dWhidden = \n",
      " [[0.    0.368]\n",
      " [0.    0.   ]\n",
      " [0.    0.368]]\n",
      "dL_dbhidden = \n",
      " [0.    0.368]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBackward Pass:\")\n",
    "print(\"dL_dWout =\", \"\\n\",dL_dWout)\n",
    "print(\"dL_dbout =\", \"\\n\", dL_dbout)\n",
    "print(\"dL_dWhidden =\",\"\\n\", dL_dWhidden)\n",
    "print(\"dL_dbhidden =\",\"\\n\", dL_dbhidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a5a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Update weights (Gradient Descent)\n",
    "# -----------------------------\n",
    "W_output -= lr * dL_dWout\n",
    "b_output -= lr * dL_dbout\n",
    "W_hidden -= lr * dL_dWhidden\n",
    "b_hidden -= lr * dL_dbhidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42554933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Parameters:\n",
      "W_hidden = \n",
      " [[ 0.2      -0.300368]\n",
      " [ 0.4       0.1     ]\n",
      " [-0.5       0.199632]]\n",
      "b_hidden = \n",
      " [-0.4       0.199632]\n",
      "W_output = \n",
      " [[-0.3     ]\n",
      " [-0.199816]]\n",
      "b_output = \n",
      " [0.10184]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUpdated Parameters:\")\n",
    "print(\"W_hidden =\",\"\\n\", W_hidden)\n",
    "print(\"b_hidden =\",\"\\n\", b_hidden)\n",
    "print(\"W_output =\", \"\\n\",W_output)\n",
    "print(\"b_output =\",\"\\n\", b_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}